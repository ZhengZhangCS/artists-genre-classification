{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport skimage\nimport os\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\nimport tensorflow as tf\n#import dataload\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Conv2D,MaxPool2D,AvgPool2D\\\n    ,Flatten","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nfrom PIL import  Image\nimport  numpy as np\nrootpath=\"../input/artists-in-genres/genre\"\nprint(os.listdir(rootpath))\n\n\nimages=[]\nlabels=[]\ndef load_data(rootpath):\n    label_num=-1\n    label2=[]\n    for d in os.listdir(rootpath):\n        label_path=rootpath+'/'+d\n        label_num= label_num+1\n        for i in os.listdir(label_path):\n            image_path=label_path+'/'+i\n            image_load = Image.open(image_path)\n            iw, ih = image_load.size  # 原始图像的尺寸\n            w, h =200,200 # 目标图像的尺寸\n            scale = min(w / iw, h / ih)  # 转换的最小比例\n\n            # 保证长或宽，至少一个符合目标图像的尺寸\n            nw = int(iw * scale)\n            nh = int(ih * scale)\n\n            image_load = image_load.resize((nw, nh), Image.BICUBIC)  # 缩小图像\n            #image.show()\n            new_image = Image.new('RGB', (200,200), (128, 128, 128))  # 生成灰色图像\n            # // 为整数除法，计算图像的位置\n            new_image.paste(image_load, ((w - nw) // 2, (h - nh) // 2))\n            image_load = np.asarray(new_image)\n            \n\n\n            #如果不是三通道 则其他GB层生成0\n            if (image_load.ndim==3):\n\n                images.append(image_load)\n            else:\n                image_load=np.expand_dims(image_load, axis=2)\n                image_load = np.concatenate((image_load, image_load, image_load), axis=-1)\n                #print(image_load.ndim)\n                #print(image_load)\n                #plt.imshow(image_load)\n                #plt.show()\n                images.append(image_load)\n            labels.append(d)\n            label2.append(label_num)\n    return images, labels,label2\n\nimages,labels,label2=load_data(rootpath)\n\nimages=np.asarray(images)\nlabel2=np.asarray(label2)\nprint(images.shape)\n\n#print(images.shape)\n\nplt.imshow(images[20])\nplt.show()\nprint(labels,label2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Validation生成\nimport random\nprint(label2.shape)\nprint(images.shape)\narr=np.arange(images.shape[0])#\nprint(arr)\n#to random index\nnp.random.shuffle(arr)\nprint(arr)\ndata=images[arr]\nlabel=label2[arr]\nprint(label)\n\nval_ratio=0.9\nindex=np.int(images.shape[0]*val_ratio)\ndata_train=data[:index]\nlabel_train=label[:index]\ndata_val=data[index:]\nlabel_val=label[index:]\n\nplt.imshow(data_val[189])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''from keras.preprocessing.image import ImageDataGenerator\n\nimage_size = 128\ndata_generator = ImageDataGenerator(validation_split=0.2)\n\n# flow_From_directory generates batches of augmented data (where augmentation can be color conversion, etc)\n# Both train & valid folders must have NUM_CLASSES sub-folders\ntrain_generator = data_generator.flow_from_directory(\n        '../input/artists-in-genres/genre',\n        target_size=(image_size, image_size),\n        batch_size=50,\n        class_mode='categorical')\n\nvalidation_generator = data_generator.flow_from_directory(\n    '../input/artists-in-genres/genre',\n    target_size=(image_size, image_size),\n    batch_size=50,\n    class_mode='categorical',\n    subset='validation') \n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport skimage\nimport os\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\nimport tensorflow as tf\n#import dataload\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Conv2D,MaxPool2D,AvgPool2D\\\n    ,Flatten,BatchNormalization,Activation\nfrom tensorflow.keras import regularizers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# model.add(Conv2D(filters=32, kernel_size=(5,5),activation='relu',input_shape=(224,224,3)))\n# model.add(MaxPool2D(2,2))\n\n# model.add(Conv2D(filters=64,kernel_size=(5,5),padding='same',activation='relu'))\n# model.add(MaxPool2D(2,2))\n\n# model.add(Conv2D(filters=128,kernel_size=(3,3),padding='same',activation='relu'))\n# model.add(MaxPool2D(2, 2))\n\n# model.add(Conv2D(filters=128,kernel_size=(3,3),padding='same',activation='relu'))\n# model.add(MaxPool2D(2, 2))\n\n# model.add(Flatten())\n\n# model.add(Dense(1024,activation='relu'))\n# model.add(Dropout(0.8))\n\n# model.add(Dense(512, activation='relu'))\n# model.add(Dense(64, activation='relu'))\n# model.add(Dense(13, activation='softmax'))\n\n# model.compile(optimizer='adam',\n#               loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n#               metrics=[\"sparse_categorical_accuracy\"])\n# model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=keras.models.Sequential()\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding='same',input_shape=(200,200,3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=2,padding='same'))\nmodel.add(Dropout(0.2))\n\n# model.add(Conv2D(filters=128,kernel_size=(3,3),padding='same')\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n\nmodel.add(Conv2D(filters=128,kernel_size=(3,3),padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=2,padding='same'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=256,kernel_size=(3,3),padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n# model.add(Conv2D(filters=256,kernel_size=(3,3),padding='same',kernel_regularizer=regularizers.l2(0.001)))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n\n# model.add(Conv2D(filters=256,kernel_size=(3,3),padding='same',kernel_regularizer=regularizers.l2(0.01)))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=2,padding='same'))\nmodel.add(Dropout(0.2))\n\n# model.add(Conv2D(filters=512,kernel_size=(3,3),padding='same',kernel_regularizer=regularizers.l2(0.001)))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n\nmodel.add(Conv2D(filters=512,kernel_size=(5,5),padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add(Conv2D(filters=512,kernel_size=(3,3),padding='same',kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=2,padding='same'))\nmodel.add(Dropout(0.2))\n\n# model.add(Conv2D(filters=512,kernel_size=(3,3),padding='same'))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n\n# model.add(Conv2D(filters=512,kernel_size=(3,3),padding='same'))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n\nmodel.add(Flatten())\n\n\n\n# model.add(Dense(1024,activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n# model.add(Dropout(0.5))\n\n\nmodel.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(13, activation='softmax'))\n\nmodel.compile(optimizer='adam',\n              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n              metrics=[\"sparse_categorical_accuracy\"])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(data_train,label_train,batch_size=64,\n        epochs = 100,\n        validation_data = (data_val,label_val),\n        \n)\n\n\n# history=model.fit(data_train,label_train,batch_size=32,\n#         epochs = 5,\n#         validation_data = (data_val,label_val),\n        \n# )\n\n\nacc=history.history['sparse_categorical_accuracy']\nval_acc=history.history['val_sparse_categorical_accuracy']\n\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nplt.subplot(1,2,1)\nplt.plot(acc,label='Train Acc')\nplt.plot(val_acc,label='Validate Acc')\nplt.title('ACC')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(loss,label='Train Loss')\nplt.plot(val_loss,label='Validate Loss')\nplt.title('Loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(data_train,label_train,batch_size=64,\n        epochs = 60,\n        validation_data = (data_val,label_val),\n        \n)\n\n\n# history=model.fit(data_train,label_train,batch_size=32,\n#         epochs = 5,\n#         validation_data = (data_val,label_val),\n        \n# )\n\n\nacc=history.history['sparse_categorical_accuracy']\nval_acc=history.history['val_sparse_categorical_accuracy']\n\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nplt.subplot(1,2,1)\nplt.plot(acc,label='Train Acc')\nplt.plot(val_acc,label='Validate Acc')\nplt.title('ACC')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(loss,label='Train Loss')\nplt.plot(val_loss,label='Validate Loss')\nplt.title('Loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport skimage\nimport os\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\nimport tensorflow as tf\n#import dataload\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Conv2D,MaxPool2D,AvgPool2D\\\n    ,Flatten","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tebsorboard\n#!rm -rf ./logs/\n#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./', histogram_freq=1)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tensorboard --logdir logs/fit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\nLOG_DIR = './' # 这里你需要输入tensorboard需要观察的文件名\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('./ngrok http 6006 &')\n! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\" --[y]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=keras.models.Sequential()\nmodel.compile(optimizer='adam',\n              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n              metrics=[\"sparse_categorical_accuracy\"])\nvgg19=tf.keras.applications.VGG19(include_top=True,weights=None,classes=13)\nmodel.add(vgg19)\nmodel.fit(data_train,label_train,batch_size=50,\n        epochs = 10,\n        validation_data = (data_val,label_val))\nvgg19.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}